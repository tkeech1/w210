{"cells":[{"cell_type":"markdown","metadata":{"id":"XC5xNrunHAgl"},"source":["# Header"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V9krbegWHIa1"},"outputs":[],"source":["import os"]},{"cell_type":"markdown","metadata":{"id":"bPQHL4liHI6T"},"source":["## Notebook Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJuHdmtHHLIT"},"outputs":[],"source":["# path to the this notebook\n","# NOTE: Replace this with your project path if needed\n","PROJECT_PATH = (\n","    \"/content/drive/My Drive/W210\"\n","    if \"google.colab\" in str(get_ipython())\n","    else \".\"\n",")\n","\n","# path to the data folder\n","# NOTE: Replace this with your data path if needed\n","DATA_PATH = f\"{PROJECT_PATH}/data\" if \"google.colab\" in str(get_ipython()) else PROJECT_PATH\n","# NOTE: For colab we use content so it doesn't load on google drive storage\n","RAW_DATA_PATH = f\"{PROJECT_PATH}/data\" if \"google.colab\" in str(get_ipython()) else f\"{PROJECT_PATH}/data\""]},{"cell_type":"markdown","metadata":{"id":"tzvE6EGWHmJn"},"source":["## Colab Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143137,"status":"ok","timestamp":1710205170804,"user":{"displayName":"Pedro Forli","userId":"08325002347257917995"},"user_tz":180},"id":"gTfRKqC-HpDj","outputId":"2b4b754d-47ae-4dbc-e4fb-d42416dddba8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["if \"google.colab\" in str(get_ipython()):\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    # setup libraries used by notebook\n","    #os.system(\"pip install -q kaggle\")\n","\n","os.chdir(PROJECT_PATH)"]},{"cell_type":"markdown","metadata":{"id":"DPLUbOgQHwyj"},"source":["## Library Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IPCWcFfY95Jk"},"outputs":[],"source":["import itertools\n","import json\n","import requests\n","import shutil\n","import typing\n","import zipfile\n","\n","from io import BytesIO\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"1knVCKXhIyWz"},"source":["## Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FEP7UeRVIyDV"},"outputs":[],"source":["def download_from_web(\n","    save_path: typing.Union[str, Path, typing.IO[bytes], typing.BinaryIO],\n","    url: str,\n","    block_size: int = 300 * 1024,\n",") -> typing.Union[typing.IO[bytes], typing.BinaryIO]:\n","    \"\"\"\n","    Perform download of a file from a public web adress\n","\n","    :param save_path: path to save the data extraction\n","    :param url: address where data is stored\n","    :param block_size: size in bytes from incremental download\n","    :return: buffer object to file\n","    \"\"\"\n","    # make sure the path points to an buffer object\n","    if isinstance(save_path, str) or isinstance(save_path, Path):\n","        file_path: typing.Union[typing.IO[bytes], typing.BinaryIO] = open(save_path, \"wb\")\n","    else:\n","        file_path = save_path\n","\n","    # generate a request to get the content\n","    response = requests.get(url, stream=True)\n","    total_size_in_bytes = int(response.headers.get(\"content-length\", 0))\n","\n","    # parse the file\n","    progress_bar = tqdm(total=total_size_in_bytes, unit=\"iB\", unit_scale=True)\n","    for data in response.iter_content(block_size):\n","        progress_bar.update(len(data))\n","        file_path.write(data)\n","    file_path.close()\n","\n","    # returns the buffer object\n","    return file_path\n","\n","# Convert packaging NDC into 11 digits\n","def convert_packaging_ndc(input_string: str) -> str:\n","    if len(input_string) == 13:\n","      result_string = input_string.replace('-', '')\n","    elif len(input_string) == 12:\n","      # Split the input string into three parts based on hyphens\n","      parts = input_string.split('-')\n","      if len(parts[0]) == 4:\n","        # Apply zero-padding to the first part\n","        parts[0] = parts[0].zfill(5)\n","        # Join the parts back together with hyphens\n","        result_string = ''.join(parts)\n","      elif len(parts[1]) == 3:\n","        # Apply zero-padding to the second part\n","        parts[1] = parts[1].zfill(4)\n","        # Join the parts back together with hyphens\n","        result_string = ''.join(parts)\n","      elif len(parts[2]) == 1:\n","        # Apply zero-padding to the third part\n","        parts[2] = parts[2].zfill(2)\n","        # Join the parts back together with hyphens\n","        result_string = ''.join(parts)\n","      else:\n","        result_string = 'Padding Error'\n","    else:\n","      result_string = 'Length Error'\n","\n","    return result_string\n","\n","# Convert product ndc into 9 digits\n","def convert_product_ndc(input_string):\n","    if len(input_string) == 10:\n","      result_string = input_string.replace('-', '')\n","    elif len(input_string) == 9:\n","      # Split the input string into two parts based on hyphens\n","      parts = input_string.split('-')\n","      if len(parts[0]) == 4:\n","        # Apply zero-padding to the first part\n","        parts[0] = parts[0].zfill(5)\n","        # Join the parts back together with hyphens\n","        result_string = ''.join(parts)\n","      elif len(parts[1]) == 3:\n","        # Apply zero-padding to the second part\n","        parts[1] = parts[1].zfill(4)\n","        # Join the parts back together with hyphens\n","        result_string = ''.join(parts)\n","      else:\n","        result_string = 'Padding Error'\n","    else:\n","      result_string = 'Length Error'\n","\n","    return result_string"]},{"cell_type":"markdown","metadata":{"id":"nWMmH4MwIC7q"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"vRCgp0L4KQTj"},"source":["# Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"se1mCPQ4KR2D"},"outputs":[],"source":["ROOT_NDC = f\"{DATA_PATH}/drug-ndc\"\n","NDC_URL = \"https://download.open.fda.gov/drug/ndc/drug-ndc-0001-of-0001.json.zip\"\n","TODAY = pd.to_datetime(\"today\").strftime(\"%Y%m%d\")"]},{"cell_type":"markdown","metadata":{"id":"hTcWKQdjP2K0"},"source":["# Data Pre-Processing"]},{"cell_type":"markdown","source":["## FDA Drug Directory"],"metadata":{"id":"Q3IzYIynJJB6"}},{"cell_type":"markdown","metadata":{"id":"fJuZqnqsQW9C"},"source":["The Drug Listing Act of 1972 requires registered drug establishments to provide the Food and Drug Administration (FDA) with a current list of all drugs manufactured, prepared, propagated, compounded, or processed by it for commercial distribution.\n","\n","The openFDA drug NDC Directory endpoint returns data from the NDC Directory, a database that contains information on the National Drug Code (NDC). FDA publishes the listed NDC numbers and the information submitted as part of the listing information in the NDC Directory which is updated daily.\n","\n","The information submitted as part of the listing process, the NDC number, and the NDC Directory are used in the implementation and enforcement of the Act."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":129557,"status":"ok","timestamp":1710205301110,"user":{"displayName":"Pedro Forli","userId":"08325002347257917995"},"user_tz":180},"id":"gW3uVN--P1zk","outputId":"3a324637-0e0a-4450-ecbd-4b6083e7a5c7"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 26.5M/26.5M [00:00<00:00, 33.6MiB/s]\n","100%|██████████| 127802/127802 [00:03<00:00, 42396.08it/s]\n","100%|██████████| 119870/119870 [00:03<00:00, 36801.44it/s]\n","100%|██████████| 135522/135522 [00:03<00:00, 36836.29it/s]\n","100%|██████████| 134544/134544 [00:03<00:00, 35185.93it/s]\n","100%|██████████| 127733/127733 [00:03<00:00, 34424.84it/s]\n","100%|██████████| 127733/127733 [00:03<00:00, 33641.02it/s]\n","100%|██████████| 128782/128782 [00:03<00:00, 34201.84it/s]\n","100%|██████████| 128782/128782 [00:03<00:00, 33558.19it/s]\n","100%|██████████| 128782/128782 [00:03<00:00, 33714.07it/s]\n","100%|██████████| 128809/128809 [00:03<00:00, 33566.25it/s]\n"]}],"source":["ndc_path = f\"{ROOT_NDC}/{TODAY} - drug-ndc-0001-of-0001.json.zip\"\n","\n","all_ndc = list()\n","all_generic_name = list()\n","all_route = list()\n","all_active_ingredients = list()\n","all_packaging = list()\n","all_manufacturer = list()\n","all_rxcui = list()\n","all_spl_set = list()\n","all_upc = list()\n","all_nui = list()\n","all_pharm_class_cs = list()\n","all_pharm_class_epc = list()\n","all_pharm_class_pe = list()\n","all_pharm_class_moa = list()\n","all_unii = list()\n","\n","if not os.path.exists(ndc_path):\n","  download_from_web(save_path=ndc_path, url=NDC_URL)\n","\n","for file_name in os.listdir(ROOT_NDC):\n","  with zipfile.ZipFile(f\"{ROOT_NDC}/{file_name}\") as z:\n","    try:\n","      raw_ndc = json.load(z.open(\"drug-ndc-0001-of-0001.json\"))\n","    except KeyError:\n","      continue\n","\n","  ndc_list = list()\n","  gen_list = list()\n","  route_list = list()\n","  ai_list = list()\n","  pack_list = list()\n","  open_fda = dict()\n","  for r in tqdm(raw_ndc[\"results\"]):\n","    id_dict = {\"product_ndc\": r[\"product_ndc\"], \"product_id\": r[\"product_id\"]}\n","\n","    ndc_dict = dict()\n","    for k, v in r.items():\n","      if isinstance(v, list) or isinstance(v, dict) or k == \"generic_name\":\n","        continue\n","      ndc_dict[k] = v\n","    ndc_list.append(ndc_dict)\n","\n","    for gn in r.get(\"generic_name\", \"\").split(\",\"):\n","      gn_dict = dict()\n","      gn_dict.update(id_dict)\n","      gn_dict[\"generic_name\"] = gn\n","      gen_list.append(gn_dict)\n","\n","    for route in r.get(\"route\", list()):\n","      route_dict = dict()\n","      route_dict.update(id_dict)\n","      route_dict[\"route\"] = route\n","      route_list.append(route_dict)\n","\n","    for i in r.get(\"active_ingredients\", list()):\n","      ai_dict = dict()\n","      ai_dict.update(id_dict)\n","      for k, v in i.items():\n","        ai_dict[k] = v\n","      ai_list.append(ai_dict)\n","\n","    for i in r.get(\"packaging\", list()):\n","      pack_dict = dict()\n","      pack_dict.update(id_dict)\n","      for k, v in i.items():\n","        pack_dict[k] = v\n","      pack_list.append(pack_dict)\n","\n","    for k, oa in r[\"openfda\"].items():\n","      if k not in open_fda:\n","        open_fda[k] = list()\n","      for v in oa:\n","        oa_dict = dict()\n","        oa_dict.update(id_dict)\n","        oa_dict[k] = v\n","        open_fda[k].append(oa_dict)\n","\n","  # create the data frames and add them to the list\n","  date = file_name[:8]\n","  all_ndc.append(pd.DataFrame(ndc_list).assign(date=date))\n","  all_generic_name.append(pd.DataFrame(gen_list).assign(date=date))\n","  all_route.append(pd.DataFrame(route_list).assign(date=date))\n","  all_active_ingredients.append(pd.DataFrame(ai_list).assign(date=date))\n","  all_packaging.append(pd.DataFrame(pack_list).assign(date=date))\n","  all_manufacturer.append(pd.DataFrame(open_fda[\"manufacturer_name\"]).assign(date=date))\n","  all_rxcui.append(pd.DataFrame(open_fda[\"rxcui\"]).assign(date=date))\n","  all_spl_set.append(pd.DataFrame(open_fda[\"spl_set_id\"]).assign(date=date))\n","  all_upc.append(pd.DataFrame(open_fda[\"upc\"]).assign(date=date))\n","  all_nui.append(pd.DataFrame(open_fda[\"nui\"]).assign(date=date))\n","  all_pharm_class_cs.append(pd.DataFrame(open_fda[\"pharm_class_cs\"]).assign(date=date))\n","  all_pharm_class_epc.append(pd.DataFrame(open_fda[\"pharm_class_epc\"]).assign(date=date))\n","  all_pharm_class_pe.append(pd.DataFrame(open_fda[\"pharm_class_pe\"]).assign(date=date))\n","  all_pharm_class_moa.append(pd.DataFrame(open_fda[\"pharm_class_moa\"]).assign(date=date))\n","  all_unii.append(pd.DataFrame(open_fda[\"unii\"]).assign(date=date))\n","\n","# parse everything into a single data frame\n","ndc_df = pd.concat(all_ndc)\n","generic_name_df = pd.concat(all_generic_name)\n","route_df = pd.concat(all_route)\n","active_ingredients_df = pd.concat(all_active_ingredients)\n","packaging_df = pd.concat(all_packaging)\n","manufacturer_df = pd.concat(all_manufacturer)\n","rxcui_df = pd.concat(all_rxcui)\n","spl_set_df = pd.concat(all_spl_set)\n","upc_df = pd.concat(all_upc)\n","nui_df = pd.concat(all_nui)\n","pharm_class_cs_df = pd.concat(all_pharm_class_cs)\n","pharm_class_epc_df = pd.concat(all_pharm_class_epc)\n","pharm_class_pe_df = pd.concat(all_pharm_class_pe)\n","pharm_class_moa_df = pd.concat(all_pharm_class_moa)\n","unii_df = pd.concat(all_unii)"]},{"cell_type":"markdown","source":["## NDC List"],"metadata":{"id":"0BHDtpDuJGDq"}},{"cell_type":"markdown","source":["!pip install -q google-colab-selenium\n","\n","import google_colab_selenium as gs\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","\n","options = Options()\n","options.add_argument(\"user-agent==Mozilla/5.0 (iPhone; CPU iPhone OS 15_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/101.0.4951.44 Mobile/15E148 Safari/604.1\")\n","\n","driver = gs.Chrome(options=options)\n","\n","driver.get(\"https://ndclist.com/ndc/0006-3941\")\n","soup = BeautifulSoup(driver.page_source)\n","\n","for info in soup.find(\"section\", {\"id\": \"product-information\"}).find_all(\"div\", {\"class\": \"row\"}):\n","  print(info)\n","  print()"],"metadata":{"id":"NQ9pqpsnLlOb"}},{"cell_type":"code","source":["from pathlib import Path\n","import os\n","import json\n","import requests\n","from bs4 import BeautifulSoup\n","\n","\n","def parse_pharamceutical_class(product_ndc, pc_string):\n","\n","  cs_info = {\n","      \"product_ndc\": product_ndc,\n","  }\n","  pe_info = {\n","      \"product_ndc\": product_ndc,\n","  }\n","  moa_info = {\n","      \"product_ndc\": product_ndc,\n","  }\n","  epc_info = {\n","      \"product_ndc\": product_ndc,\n","  }\n","\n","  if pc_string is not None:\n","\n","    pcs = pc_string.strip().split(',')\n","\n","    for pc in pcs:\n","      if '[CS]' in pc:\n","        cs_info = {\n","            \"product_ndc\": product_ndc,\n","            \"pharm_class_cs\": pc\n","        }\n","      if '[PE]' in pc:\n","        pe_info = {\n","            \"product_ndc\": product_ndc,\n","            \"pharm_class_pe\": pc\n","        }\n","      if '[MoA]' in pc:\n","        moa_info = {\n","            \"product_ndc\": product_ndc,\n","            \"pharm_class_moa\": pc\n","        }\n","      if '[EPC]' in pc:\n","        epc_info = {\n","            \"product_ndc\": product_ndc,\n","            \"pharm_class_epc\": pc\n","        }\n","\n","  return cs_info, pe_info, moa_info, epc_info\n","\n","\n","def get_ndc_data(ndc: str):\n","  url = f\"https://www.hipaaspace.com/medical_billing/coding/national.drug.codes/{ndc}.json\"\n","  response = requests.get(url)\n","\n","  path = Path(f\"{DATA_PATH}/_search\")\n","  path.mkdir(exist_ok=True, parents=True)\n","  try:\n","    with open(path / f\"{ndc}.json\", \"r\") as f:\n","      ndc_data = json.load(f)\n","  except:\n","    if f\"{ndc}.json\" not in os.listdir(path):\n","      soup = BeautifulSoup(response.text)\n","      json_content = soup.find('code')\n","      try:\n","        ndc_data = json.loads(json_content.contents[0])\n","      except AttributeError:\n","        return\n","      with open(path / f\"{ndc}.json\", \"w\") as f:\n","        json.dump(ndc_data, f)\n","\n","\n","  ndc_info = {\n","    \"product_ndc\": ndc_data['NDC']['ProductNDC'],\n","    \"labeler_name\": ndc_data['NDC']['LabelerName'],\n","    \"brand_name\": ndc_data['NDC']['ProprietaryName'],\n","    \"brand_name_suffix\": ndc_data['NDC']['ProprietaryNameSuffix'],\n","    #\"finished\": ndc_data['NDC']['NDCCode'],\n","    \"listing_expiration_date\": ndc_data['NDC']['ListingRecordCertifiedThrough'],\n","    \"marketing_category\": ndc_data['NDC']['MarketingCategoryName'],\n","    \"dosage_form\": ndc_data['NDC']['DosageFormName'],\n","    # \"spl_id\": ndc_data['NDC']['NDCCode'],\n","    \"product_type\": ndc_data['NDC']['ProductTypeName'],\n","    \"marketing_start_date\": ndc_data['NDC']['StartMarketingDate'],\n","    \"application_number\": ndc_data['NDC']['ApplicationNumber'],\n","    \"brand_name_base\": ndc_data['NDC']['ProprietaryName'],\n","    \"marketing_end_date\": ndc_data['NDC']['EndMarketingDatePackage'],\n","    \"dea_schedule\": ndc_data['NDC']['DEASchedule'],\n","    \"status\": ndc_data['NDC']['Status'],\n","  }\n","\n","  generic_info = {\n","      \"product_ndc\": ndc_data['NDC']['ProductNDC'],\n","      \"generic_name\": ndc_data['NDC']['NonProprietaryName'],\n","  }\n","\n","  route_info = {\n","      \"product_ndc\": ndc_data['NDC']['ProductNDC'],\n","      \"route\": ndc_data['NDC']['RouteName'],\n","  }\n","\n","  active_ingredient_info = {\n","      \"product_ndc\": ndc_data['NDC']['ProductNDC'],\n","      \"name\": ndc_data['NDC']['NonProprietaryName'],\n","  }\n","  if ndc_data['NDC']['StrengthNumber'] is not None and ndc_data['NDC']['StrengthUnit'] is not None:\n","    active_ingredient_info = {\n","        \"product_ndc\": ndc_data['NDC']['ProductNDC'],\n","        \"name\": ndc_data['NDC']['NonProprietaryName'],\n","        \"strength\": ndc_data['NDC']['StrengthNumber'] + \" \" + ndc_data['NDC']['StrengthUnit'],\n","    }\n","\n","  manufacturer_info = {\n","      \"product_ndc\": ndc_data['NDC']['ProductNDC'],\n","      \"manufacturer_name\": ndc_data['NDC']['LabelerName'],\n","  }\n","\n","  unii_info = {\n","      \"product_ndc\": ndc_data['NDC']['ProductNDC'],\n","      \"unii\": None,\n","      \"substance_name\": ndc_data['NDC']['SubstanceName'],\n","  }\n","\n","  packaging_info = {\n","      \"product_ndc\": ndc_data['NDC']['ProductNDC'],\n","      \"package_ndc\": ndc,\n","      \"description\": ndc_data['NDC']['PackageDescription'],\n","      \"sample\": \"\",\n","      \"marketing_start_date\": ndc_data['NDC']['StartMarketingDate'],\n","      \"marketing_end_date\": ndc_data['NDC']['EndMarketingDatePackage'],\n","  }\n","\n","  pc_cs_info, pc_pe_info, pc_moa_info, pc_epc_info = parse_pharamceutical_class(ndc_data['NDC']['ProductNDC'], ndc_data['NDC']['Pharm_Classes'])\n","\n","  return ndc_info, generic_info, route_info, active_ingredient_info, manufacturer_info, unii_info, packaging_info, pc_cs_info, pc_pe_info, pc_moa_info, pc_epc_info"],"metadata":{"id":"P-F9Vf52Snc8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs = dict()\n","fda_list = list(set(packaging_df[\"package_ndc\"].to_list()))\n","\n","ndcs_to_parse = list()\n","for i in tqdm(range(100)):\n","    # get a list of all labelers\n","    r = requests.get(f\"https://www.hipaaspace.com/medical.coding.library/national.drug.code.directory/{i:02d}\")\n","    links = [a[\"href\"] for a in BeautifulSoup(r.text).find_all(\"a\", {\"class\": \"lookup_item_title\"})]\n","\n","    for href in links:\n","        r = requests.get(href)\n","        ndcs = [a[\"href\"].split(\"/\")[-1] for a in BeautifulSoup(r.text).find_all(\"a\", {\"class\": \"lookup_item_title\"})]\n","\n","        for ndc in ndcs:\n","            if ndc not in fda_list:\n","                ndcs_to_parse.append(ndc)\n","\n","for ndc in tqdm(ndcs_to_parse):\n","    outputs[ndc] = get_ndc_data(ndc)"],"metadata":{"id":"KDvtuplfQ2Rc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6713b42-2af0-4ba5-91c7-f94e9e8618ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [5:25:03<00:00, 195.03s/it]\n"," 25%|██▍       | 67107/271552 [18:30:28<34:38:11,  1.64it/s]"]}]},{"cell_type":"markdown","metadata":{"id":"zZIi3_B5_auc"},"source":["# Export"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQ-XZx2U_a5V"},"outputs":[],"source":["ndc_df.to_parquet(f\"{DATA_PATH}/preprocessed/ndc.parquet\", index=False)\n","generic_name_df.to_parquet(f\"{DATA_PATH}/preprocessed/generic_name.parquet\", index=False)\n","route_df.to_parquet(f\"{DATA_PATH}/preprocessed/route.parquet\", index=False)\n","active_ingredients_df.to_parquet(f\"{DATA_PATH}/preprocessed/active_ingredients.parquet\", index=False)\n","packaging_df.assign(\n","    ndc=lambda f: f[\"package_ndc\"].apply(convert_packaging_ndc)\n",").to_parquet(f\"{DATA_PATH}/preprocessed/packaging.parquet\", index=False)\n","manufacturer_df.to_parquet(f\"{DATA_PATH}/preprocessed/manufacturer.parquet\", index=False)\n","rxcui_df.to_parquet(f\"{DATA_PATH}/preprocessed/rxcui.parquet\", index=False)\n","spl_set_df.to_parquet(f\"{DATA_PATH}/preprocessed/spl_set.parquet\", index=False)\n","upc_df.to_parquet(f\"{DATA_PATH}/preprocessed/upc.parquet\", index=False)\n","nui_df.to_parquet(f\"{DATA_PATH}/preprocessed/nui.parquet\", index=False)\n","pharm_class_cs_df.to_parquet(f\"{DATA_PATH}/preprocessed/pharm_class_cs.parquet\", index=False)\n","pharm_class_epc_df.to_parquet(f\"{DATA_PATH}/preprocessed/pharm_class_epc.parquet\", index=False)\n","pharm_class_pe_df.to_parquet(f\"{DATA_PATH}/preprocessed/pharm_class_pe.parquet\", index=False)\n","pharm_class_moa_df.to_parquet(f\"{DATA_PATH}/preprocessed/pharm_class_moa.parquet\", index=False)\n","unii_df.to_parquet(f\"{DATA_PATH}/preprocessed/unii.parquet\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"dknQosE5cUDl"},"source":["---"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}